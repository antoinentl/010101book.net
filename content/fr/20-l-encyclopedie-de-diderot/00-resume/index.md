---
layout: page
title: Résumé
chapter: L'encyclopédie de Diderot et autres bases textuelles
permalink: /fr/l-encyclopedie-de-diderot/resume/
order: 2001
published: true
---
<p>Le Projet ARTFL (American and French Research on the Treasury of the French Language – Recherche franco-américaine sur les trésors de la langue française) met en ligne en 1998 la base de données du premier volume (1751) de l’<em>Encyclopédie</em> de Diderot et d’Alembert. Destinée à rassembler puis divulguer les connaissances de l'époque, l’Encyclopédie porte la marque des courants intellectuels et sociaux du Siècle des Lumières, qui aboutiront à la Révolution française de 1789. Cette mise en ligne expérimentale est la première étape vers une base de données exhaustive comprenant l'<em>Encyclopédie</em> (1751-1772) dans son entier, à savoir dix-sept volumes de texte et onze volumes de planches. L’ARTFL travaille également à d’autres projets, par exemple une base de données exhaustive des différentes éditions du <em>Dictionnaire de l’Académie française</em> (1694-1935).</p>

<p>Le Projet ARTFL est un projet commun du CNRS (Centre national de la recherche scientifique) en France et de l'Université de Chicago dans l’Illinois. Ce projet a pour but de constituer une base de données de 2.000 ouvrages des 13e-20e siècles ayant trait à la littérature, à la philosophie, aux arts ou aux sciences.</p>

<p>En 1998, le Projet ARTFL met en ligne la base de données du premier volume (1751) de l'<em>Encyclopédie</em> de Diderot et d’Alembert. Cette mise en ligne expérimentale est le prélude à une base de données exhaustive comprenant l'<em>Encyclopédie</em> dans son entier, à savoir dix-sept volumes de texte (soit 18.000 pages et 21,7 millions de mots) et onze volumes de planches, avec des planches d’une telle qualité technique qu’elles font toujours référence dans leur domaine à l’heure actuelle.</p>

<p>La première édition (1751-1772) de l’<em>Encyclopédie ou Dictionnaire raisonné des sciences, des métiers et des arts</em> comprend 72.000 articles rédigés par 140 collaborateurs, dont Rousseau, d'Alembert, Voltaire, Marmontel, d'Holbach, Turgot, etc. Une encyclopédie collective donc, bien avant Wikipédia. Monumental ouvrage de référence destiné à rassembler puis divulguer les connaissances de l'époque, l'<em>Encyclopédie</em> porte la marque des courants intellectuels et sociaux du Siècle des Lumières. C'est grâce à elle que se propagent les idées nouvelles qui inspireront la Révolution française de 1789.</p>

<p>Dans l’<em>Encyclopédie</em>, Diderot explique lui-même que «le but d’une encyclopédie est de rassembler les connaissances éparses sur la surface de la terre, d’en exposer le système général aux hommes avec qui nous vivons et de le transmettre aux hommes qui viendront après nous, afin (…) que nos neveux, devenant plus instruits, deviennent en même temps plus vertueux et plus heureux, et que ne mourions pas sans avoir bien mérité du genre humain.» Un beau texte qui figure aussi sur un mur de l’Allée de l’Encyclopédie, l’une des grandes artères de la Bibliothèque nationale de France (BnF).</p>

<p>Disponible sur le site de l’ARTFL en 1998, la base de données du premier volume permet une recherche par mot, par portion de texte, par auteur ou par catégorie, ou en combinant ces critères entre eux. Des liens hypertextes permettent de passer des articles aux planches et des versions numériques au fac-similé des pages originales. L'automatisation complète des procédures de saisie entraîne des erreurs typographiques et des erreurs d'identification qui sont corrigées au fil des mois. La recherche d'images est possible dans un deuxième temps.</p>

<p>L'ARTFL travaille également à une base de données exhaustive du <em>Dictionnaire de l'Académie française</em>, dont les différentes éditions s’échelonnent entre 1694 et 1935. La première édition (1694) et la cinquième édition (1798) du dictionnaire sont les premières à être disponibles en ligne, avec possibilité de recherche par mot puis par portion de texte. Les différentes éditions sont ensuite combinées dans une base de données unique, qui permet de juger de l'évolution d'un terme en consultant aussi bien une édition spécifique que l'ensemble des éditions.</p>

<p>D’autres projets de l'ARTFL concernent par exemple le <em>Dictionnaire historique et critique</em> de Philippe Bayle dans son édition de 1740, le <em>Roget's Thesaurus</em> de 1911, le <em>Webster's Revised Unabridged Dictionary</em> de 1913, le <em>Thresor de la langue française</em> de Jean Nicot imprimé en 1606, ou encore un projet biblique multilingue comprenant entre autres <em>La Bible française</em> de Louis Segond, publiée en 1910. Il s’agit là encore de bases de données avec moteur de recherche. La technologie au service de la littérature, donc.</p>

<p>Outre sa collaboration avec l’ARTFL pour l’<em>Encyclopédie </em>de Diderot et d’Alembert, le laboratoire ATILF (Analyse et traitement informatique de la langue française) gère plusieurs bases textuelles payantes, par exemple Frantext, un corpus à dominante littéraire débuté en 1995 par l’Institut national de la langue française (INaLF, ancêtre de l’ATILF). En janvier 1998, Frantext inclut un corpus représentatif couvrant cinq siècles (16e-20e siècles), avec 180 millions de mots-occurrences provenant de 3.500 unités textuelles en arts, sciences et techniques. 82 centres de recherche et bibliothèques universitaires d'Europe, d'Australie, du Japon et du Canada sont abonnés à Frantext, ce qui représente 1.250 postes de travail, avec une cinquantaine d’interrogations de la base par jour.</p>

<p>Dans sa section Dictionnaires de l’ATILF (en accès libre), l’ATILF propose aussi une collection de dictionnaires informatisés comprenant les dictionnaires de Robert Estienne (1552), Jean Nicot (1606) et Pierre Bayle (1740), plusieurs éditions des dictionnaires de l’Académie française (1694, 1798, 1835, 1932-1935, 1992) et enfin le <em>Trésor de la langue française informatisé</em> (TLFi, 1971-1994).</p>

<p>Émilie Devriendt, élève professeure à l’Ecole normale supérieure (ENS) de Paris, écrit en juin 2001: «L’avenir me semble prometteur en matière de publications de ressources en ligne, même si, en France tout au moins, bon nombre de résistances, inhérentes aux systèmes universitaire et éditorial, ne risquent pas de céder du jour au lendemain (dans dix, vingt ans, peut-être ?). Ce qui me donne confiance, malgré tout, c’est la conviction de la nécessité pratique d’internet. J’ai du mal à croire qu’à terme, un chercheur puisse se passer de cette gigantesque bibliothèque, de ce formidable outil. Ce qui ne veut pas dire que les nouvelles pratiques de recherche liées à internet ne doivent pas être réfléchies, mesurées à l’aune de méthodologies plus traditionnelles, bien au contraire. Il y a une histoire de l’"outillage", du travail intellectuel, où internet devrait avoir sa place.»</p>

<p>Elle fait à nouveau le point sur le sujet en février 2003: «Dans ce domaine que l’on appelle parfois l’informatique littéraire, deux aspects du texte électronique m’intéressent plus particulièrement, dans une perspective d’enseignement ou de recherche: la publication de ressources textuelles, par exemple littéraires, sur le web en mode texte ou en mode image (exemple: Gallica ou la Bibliothèque électronique de Lisieux); la publication de bases de données textuelles interactives, c’est à dire d’outils de recherche et d’analyse linguistique appliqués à des textes électroniques donnés (exemple: la Nefbase du Net des études françaises (NEF) ou, si l’on veut citer une banque de données payante, Frantext). Aujourd’hui ce type de ressources est relativement bien développé (même si aucune "explosion" ne semble avoir eu lieu si l’on compare la situation actuelle à celle d’il y a deux ou trois ans). En revanche, on ne peut véritablement mesurer les usages qui en sont faits.»</p>

<p>Question cruciale qui suscite de nombreux débats, l’accès à ces bases de données doit-il être gratuit ou payant? Eduard Hovy, directeur du Natural Language Group (Groupe du langage naturel) de l’USC/ISI (University of Southern California / Information Sciences Institute – Université de la Californie du Sud / Institut en sciences de l’information), donne son sentiment sur ce point en septembre 2000: «En tant qu’universitaire, je suis bien sûr un des parasites de notre société [une remarque à prendre au deuxième degré, ndlr], et donc tout à fait en faveur de l’accès libre à la totalité de l’information. En tant que co-propriétaire d’une petite start-up, je suis conscient du coût représenté par la collecte et le traitement de l’information, et de la nécessité de faire payer ce service d’une manière ou d’une autre. Pour équilibrer ces deux tendances, je pense que l’information à l’état brut et certaines ressources à l’état brut (langages de programmation ou moyens d’accès à l’information de base comme les navigateurs web) doivent être disponibles gratuitement. Ceci crée un marché et permet aux gens de les utiliser. Par contre l’information traitée doit être payante, tout comme les systèmes permettant d’obtenir et de structurer très exactement ce dont on a besoin. Cela permet de financer ceux qui développent ces nouvelles technologies.»</p>

<p>Bases de données payantes à destination de ceux qui en ont les moyens, ou bases de données gratuites à la disposition de tous? Les nouveaux outils dont on dispose pour créer et gérer des bases textuelles à moindres frais permettent de pencher vers la deuxième solution, tout au moins lorsqu’il existe une volonté dans ce sens. Professeur au département d’études françaises de l’Université de Toronto (Canada), Russon Wooldridge est le créateur de ressources littéraires librement accessibles en ligne. En 2001, sa tâche se trouve facilitée par le logiciel TACTweb (TACT: Text Analysis Computing Tools – Outils informatiques pour l’analyse des textes). Développé par John Bradley, informaticien au King’s College London (Royaume-Uni), et par Geoffrey Rockwell, professeur à l’Université McMaster (Canada), TACTweb est un logiciel de recherche de données textuelles en ligne. Russon Wooldridge explique en mai 2001: «La dernière version de TACTweb permet dorénavant de construire des bases interactives importantes comme les dictionnaires de la Renaissance (Estienne et Nicot ; base RenDico), les deux principales éditions du <em>Dictionnaire de l’Académie française</em> (1694 et 1835), les collections de la Bibliothèque électronique de Lisieux (base LexoTor), les œuvres complètes de Maupassant, ou encore les théâtres complets de Corneille, Molière, Racine, Marivaux et Beaumarchais (base théâtre 17e-18e). À la différence de grosses bases comme Frantext ou ARTFL nécessitant l’intervention d’informaticiens professionnels, d’équipes de gestion et de logiciels coûteux, TACTweb, qui est un gratuiciel que l’on peut décharger en ligne et installer soi-même, peut être géré par le chercheur individuel créateur de ressources textuelles en ligne.»</p>

<p>Autre exemple, le projet HyperNietzsche, lancé en 2000 sous la direction de Paolo d’Iorio, chargé de recherches à l’Institut des textes et manuscrits modernes (ITEM) du CNRS en France. D’après son site web, ce projet expérimental, en accès libre et gratuit, «vise à créer une infrastructure de travail collectif en réseau. Cette infrastructure sera d’abord appliquée et testée sur l’œuvre de Nietzsche, pour être ensuite généralisable à d’autres auteurs, à l’étude d’une période historique ou d’un fonds d’archive, ou à l’analyse d’un problème philosophique. Il ne s’agit donc pas seulement d’un projet de numérisation et de mise en réseau d’un ensemble de textes et d’études sur Nietzsche, ni d’une édition électronique conçue comme un produit confectionné et offert à la consultation, mais plutôt d’un instrument de travail permettant à une communauté savante délocalisée de travailler de façon coopérative et cumulative et de publier les résultats de son travail en réseau, à l’échelle de la planète. Il ne s’agit pas seulement d’une bibliothèque de textes électroniques en ligne, plus ou moins bien indexée, accompagnée d’un moteur de recherche par mots-clés ou en texte intégral. C’est un véritable système hypertextuel qui permet tout d’abord de disposer les textes et les manuscrits de Nietzsche selon des ordonnancements chronologiques, génétiques ou thématiques, et surtout d’activer un ensemble de liens hypertextuels qui relient les sources primaires aux essais critiques produits par les chercheurs.» Le texte intégral consacré à la présentation du projet est disponible en accès libre pendant deux ans sur le site des PUF (Presses universitaires de France). Son équivalent imprimé est disponible en octobre 2000 sous le titre <em>HyperNietzsche</em> et publié dans la série Écritures électroniques de la collection Que sais-je?</p>

<p>Mais certains préfèrent la rentabilité économique à la diffusion gratuite du savoir, y compris pour les œuvres tombées dans le domaine public. On a d’une part des éditeurs électroniques qui vendent notre patrimoine en version numérique, d’autre part des bibliothèques numériques qui diffusent gratuitement ce patrimoine à l’échelle de la planète. De même, on a d’une part des organismes publics et privés qui monnaient leurs bases de données au prix fort, d’autre part des éditeurs et des universités qui mettent leurs publications et leurs cours en accès libre sur le web. Reste à savoir si, pour les premiers, les profits dégagés en valent vraiment la peine. Dans de nombreux cas, il semblerait que la somme nécessaire à la gestion interne soit au moins équivalente sinon supérieure aux gains réalisés. Est-il vraiment utile de mettre un pareil frein à la diffusion de l’information pour un profit finalement nul? On ne compte plus les organismes qui font passer leurs projets du payant au gratuit, avec un usage accru de leurs services et une explosion du nombre de leurs usagers.</p>